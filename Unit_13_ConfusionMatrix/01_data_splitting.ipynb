{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9f541c",
   "metadata": {},
   "source": [
    "---\n",
    "**Data Splitting**\n",
    "\n",
    "Often times just training a model is not enough. We also need to test its performance. For this purpose we again need some data to test our model against.\n",
    "\n",
    "To solve this, we split our original dataset into two subsets, namely -\n",
    "- `Training dataset` : used to train the model and find weights and all.\n",
    "- `Testing dataset` : used to test the model i.e. if the calculated weights can calculate the results accurately enough.\n",
    "\n",
    "For this purpose we use the `train_test_split` function from `sklearn.model_selection` module. It takes the following parameters:\n",
    "- `X values`: list of values for the independent variables\n",
    "- `Y values`:  list of values for the dependent/target variable\n",
    "- `test_size`: (default = 0.25) fraction proportional to test dataset\n",
    "- `random_state`: (optional) controls the shuffling, used to replicate same random state again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9503c435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [[18], [7], [14], [5], [3], [6], [15], [10], [8], [17], [12], [4], [1], [16], [13]] [1800, 700, 1400, 500, 300, 600, 1500, 1000, 800, 1700, 1200, 400, 100, 1600, 1300]\n",
      "Test: [[19], [2], [20], [9], [11]] [1900, 200, 2000, 900, 1100]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample data (features and labels)\n",
    "X = [[1], [2], [3], [4], [5]]\n",
    "y = [100, 200, 300, 400, 500]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "print(\"Train:\", X_train, y_train)\n",
    "print(\"Test:\", X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c2d7a",
   "metadata": {},
   "source": [
    "In this example we can see that\n",
    "- we first split the iris dataset into train & test datasets, then\n",
    "- we trained a logistic regresison model on the train dataset, then\n",
    "- we test the models accuracy using the test dataset\n",
    "\n",
    "_Note: Accuracy is fraction value that tells how many predictions are correct out of the total predictions made._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c14e9e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load sample data\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test model\n",
    "print(f\"Accuracy: {model.score(X_test, y_test):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
